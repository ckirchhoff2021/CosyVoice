import gradio as gr
import requests
import torch
import torchaudio
import numpy as np
import os
import uuid

# é»˜è®¤å‚æ•°
DEFAULT_HOST = "0.0.0.0"
DEFAULT_PORT = 8000

def tts_inference(text, mode="sft", spk_id="ä¸­æ–‡å¥³", prompt_text="", prompt_wav=None, instruct_text=""):
    """
    è°ƒç”¨TTSæœåŠ¡è¿›è¡Œè¯­éŸ³åˆæˆ
    """
    try:
        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
        unique_id = str(uuid.uuid4())[:8]
        output_wav = f"tts_output_{unique_id}.wav"
        
        url = f"http://{DEFAULT_HOST}:{DEFAULT_PORT}/inference_{mode}"
        
        if mode == 'sft':
            payload = {
                'tts_text': text,
                'spk_id': spk_id
            }
            response = requests.request("GET", url, data=payload, stream=True)
        elif mode == 'zero_shot':
            payload = {
                'tts_text': text,
                'prompt_text': prompt_text
            }
            # å¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘æ–‡ä»¶
            if prompt_wav is not None:
                files = [('prompt_wav', ('prompt_wav', open(prompt_wav, 'rb'), 'application/octet-stream'))]
                response = requests.request("GET", url, data=payload, files=files, stream=True)
            else:
                # ä½¿ç”¨é»˜è®¤çš„å‚è€ƒéŸ³é¢‘
                payload['prompt_text'] = "å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚" if not prompt_text else prompt_text
                files = [('prompt_wav', ('prompt_wav', open('asset/zero_shot_prompt.wav', 'rb'), 'application/octet-stream'))]
                response = requests.request("GET", url, data=payload, files=files, stream=True)
        elif mode == 'cross_lingual':
            payload = {
                'tts_text': text,
            }
            if prompt_wav is not None:
                files = [('prompt_wav', ('prompt_wav', open(prompt_wav, 'rb'), 'application/octet-stream'))]
                response = requests.request("GET", url, data=payload, files=files, stream=True)
            else:
                # ä½¿ç”¨é»˜è®¤çš„å‚è€ƒéŸ³é¢‘
                files = [('prompt_wav', ('prompt_wav', open('asset/cross_lingual_prompt.wav', 'rb'), 'application/octet-stream'))]
                response = requests.request("GET", url, data=payload, files=files, stream=True)
        else:  # instruct2æ¨¡å¼
            if not prompt_wav:
                prompt_wav = 'asset/zero_shot_prompt.wav'
            
            files = [('prompt_wav', ('prompt_wav', open(prompt_wav, 'rb'), 'application/octet-stream'))]
            payload = {
                'tts_text': text,
                'instruct_text': instruct_text,
            }
            response = requests.request("GET", url, data=payload, files=files, stream=True)
        
        # å¤„ç†å“åº”
        tts_audio = b''
        for r in response.iter_content(chunk_size=16000):
            tts_audio += r
        
        # è½¬æ¢éŸ³é¢‘æ•°æ®
        tts_speech = torch.from_numpy(np.array(np.frombuffer(tts_audio, dtype=np.int16))).unsqueeze(dim=0)
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        torchaudio.save(output_wav, tts_speech, 22050)
        
        return output_wav
    except Exception as e:
        print(f"Error in TTS inference: {e}")
        return None

def openai_tts(text, voice="wise"):
    """
    è°ƒç”¨OpenAIå…¼å®¹çš„TTSæœåŠ¡
    """
    try:
        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
        unique_id = str(uuid.uuid4())[:8]
        output_wav = f"tts_output_{unique_id}.wav"
        
        url = f"http://{DEFAULT_HOST}:{DEFAULT_PORT}/v1/audio/speech"
        payload = {
            'input': text,
            'voice': voice
        }
        response = requests.request("POST", url, json=payload, stream=True)
        
        # å¤„ç†å“åº”
        tts_audio = b''
        for r in response.iter_content(chunk_size=16000):
            tts_audio += r
        
        # è½¬æ¢éŸ³é¢‘æ•°æ®
        tts_speech = torch.from_numpy(np.array(np.frombuffer(tts_audio, dtype=np.int16))).unsqueeze(dim=0)
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        torchaudio.save(output_wav, tts_speech, 22050)
        
        return output_wav
    except Exception as e:
        print(f"Error in OpenAI TTS: {e}")
        return None

def generate_speech(text, mode, spk_id, prompt_text, prompt_wav, voice, instruct_text):
    """
    Gradioæ¥å£å‡½æ•°
    """
    if not text.strip():
        return None, "è¯·è¾“å…¥è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬"
    
    # æ£€æŸ¥TTSæœåŠ¡æ˜¯å¦å¯ç”¨
    try:
        requests.get(f"http://{DEFAULT_HOST}:{DEFAULT_PORT}/")
    except requests.exceptions.ConnectionError:
        return None, f"æ— æ³•è¿æ¥åˆ°TTSæœåŠ¡ (http://{DEFAULT_HOST}:{DEFAULT_PORT})ï¼Œè¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ"
    
    if mode == "openai":
        wav_file = openai_tts(text, voice)
    else:
        wav_file = tts_inference(text, mode, spk_id, prompt_text, prompt_wav, instruct_text)
    
    if wav_file and os.path.exists(wav_file):
        return wav_file, f"è¯­éŸ³åˆæˆæˆåŠŸï¼æ¨¡å¼: {mode}"
    else:
        return None, "è¯­éŸ³åˆæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡å’Œå‚æ•°è®¾ç½®"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="TTSè¯­éŸ³åˆæˆæ¼”ç¤º") as demo:
    gr.Markdown("# ğŸµ TTSè¯­éŸ³åˆæˆæ¼”ç¤º")
    gr.Markdown("å°†æ–‡æœ¬è½¬æ¢ä¸ºè‡ªç„¶æµç•…çš„è¯­éŸ³")
    
    with gr.Row():
        with gr.Column():
            text_input = gr.Textbox(
                label="è¾“å…¥æ–‡æœ¬",
                placeholder="è¯·è¾“å…¥è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬...",
                lines=3,
                value="ä½ å¥½ï¼Œæˆ‘æ˜¯çˆ±æ–°è§‰ç½—ç„çƒ¨ï¼Œä½ æ˜¯æœ‰ä»€ä¹ˆäº‹æƒ…è¦ç¦€æŠ¥å—ï¼Ÿ"
            )
            
            mode = gr.Radio(
                choices=["sft", "zero_shot", "cross_lingual", "instruct2", "openai"], # instruct2 for cosyvoice2
                value="openai",
                label="åˆæˆæ¨¡å¼"
            )
            
            with gr.Group():
                gr.Markdown("### æ¨¡å¼å‚æ•°è®¾ç½®")
                spk_id = gr.Textbox(label="è¯´è¯äººID", value="ä¸­æ–‡å¥³")
                voice = gr.Textbox(label="å£°éŸ³ç±»å‹(OpenAIæ¨¡å¼)", value="wise")
                
                instruct_text = gr.Textbox(
                    label="Instructæ–‡æœ¬(Instructæ¨¡å¼)", 
                    value="ç”¨å››å·è¯è¯´è¿™å¥è¯"
                )
                
                prompt_text = gr.Textbox(
                    label="å‚è€ƒæ–‡æœ¬(Zero-shot/Cross-lingualæ¨¡å¼)", 
                    value="å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚"
                )
                
                prompt_wav = gr.Audio(
                    label="å‚è€ƒéŸ³é¢‘(Zero-shot/Cross-lingualæ¨¡å¼)", 
                    type="filepath"
                )
            
            generate_btn = gr.Button("ç”Ÿæˆè¯­éŸ³", variant="primary")
            
        with gr.Column():
            audio_output = gr.Audio(label="åˆæˆè¯­éŸ³")
            status_output = gr.Textbox(label="çŠ¶æ€ä¿¡æ¯", interactive=False)
    
    # ç¤ºä¾‹
    gr.Examples(
        examples=[
            ["ä½ å¥½ï¼Œæˆ‘æ˜¯è¶…çº§æ— æ•Œç ´åç¥ï¼Œä½ æ‰¾æˆ‘æœ‰äº‹å—ï¼Ÿ", "sft", "ä¸­æ–‡å¥³", "", None, "wise"],
            ["å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œæˆ‘æ˜¯çˆ±æ–°è§‰ç½—ç„çƒ¨ã€‚", "zero_shot", "ä¸­æ–‡å¥³", "å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚", "asset/zero_shot_prompt.wav", "wise"],
            ["Hello, I am your daddy, I am a super powerful destroyer.", "cross_lingual", "", "", "asset/cross_lingual_prompt.wav", "wise"]
        ],
        inputs=[text_input, mode, spk_id, prompt_text, prompt_wav, voice, instruct_text],
        outputs=[audio_output, status_output],
        fn=generate_speech,
        cache_examples=False
    )
    
    # äº‹ä»¶å¤„ç†
    generate_btn.click(
        fn=generate_speech,
        inputs=[text_input, mode, spk_id, prompt_text, prompt_wav, voice, instruct_text],
        outputs=[audio_output, status_output]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7861, share=True)
